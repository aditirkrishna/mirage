{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIRAGE++ Notebook 2: Core Model Walkthrough\n",
    "\n",
    "## Building the Entropy-Regularized Mirror Descent Linear Regression\n",
    "\n",
    "In this notebook, we'll build the MIRAGE++ model step by step. We'll explain every part in plain English, show the code, and visualize how the model learns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What is Entropy Regularization?\n",
    "\n",
    "Entropy regularization encourages the model's weights to be spread out, not concentrated on just a few features. This is like making a portfolio diversified instead of betting everything on one asset.\n",
    "\n",
    "Mathematically: $H(\\theta) = -\\sum_i \\theta_i \\log \\theta_i$\n",
    "\n",
    "We add this to the loss function to penalize 'spiky' weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. What is Mirror Descent?\n",
    "\n",
    "Mirror descent is a smarter way to update weights than regular gradient descent. Instead of moving in a straight line, it moves in a way that respects the geometry of the problem (e.g., keeping weights positive and summing to 1).\n",
    "\n",
    "We use the KL-divergence as our 'distance' measure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. The MIRAGE++ Loss Function\n",
    "\n",
    "Our loss combines mean squared error (MSE) and entropy regularization:\n",
    "\n",
    "$L(\\theta) = \\|X\\theta - y\\|^2 + \\lambda H(\\theta)$\n",
    "\n",
    "Where $\\lambda$ controls how much we care about entropy."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def entropy(theta, epsilon=1e-8):\n",
    "    theta = np.clip(theta, epsilon, 1.0)\n",
    "    return -np.sum(theta * np.log(theta))\n",
    "\n",
    "def loss(X, y, theta, lam):\n",
    "    preds = X @ theta\n",
    "    mse = np.mean((preds - y)**2)\n",
    "    ent = entropy(theta)\n",
    "    return mse + lam * ent\n",
    "\n",
    "# Example usage\n",
    "X = np.random.randn(100, 5)\n",
    "true_theta = np.array([0.2, 0.1, 0.4, 0.1, 0.2])\n",
    "y = X @ true_theta + np.random.randn(100) * 0.1\n",
    "theta = np.ones(5) / 5\n",
    "print('Initial loss:', loss(X, y, theta, lam=0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Mirror Descent Update Rule\n",
    "\n",
    "Instead of subtracting the gradient (as in gradient descent), we multiply by the exponent of the negative gradient. This keeps weights positive and, after normalization, on the simplex (like probabilities).\n",
    "\n",
    "$\\theta_{t+1} = \\theta_t \\cdot \\exp(-\\eta \\nabla L(\\theta_t))$\n",
    "\n",
    "Then normalize so $\\sum_i \\theta_i = 1$."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def mirror_descent_step(grad, theta_t, eta):\n",
    "    theta_new = theta_t * np.exp(-eta * grad)\n",
    "    theta_new = np.clip(theta_new, 1e-12, None)\n",
    "    return theta_new / np.sum(theta_new)\n",
    "\n",
    "# Example gradient\n",
    "grad = np.random.randn(5)\n",
    "theta_new = mirror_descent_step(grad, theta, eta=0.1)\n",
    "print('Updated theta:', theta_new)\n",
    "print('Sum of theta:', np.sum(theta_new))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Full Model Training Loop\n",
    "\n",
    "Let's put it all together: initialize weights, compute gradient, update with mirror descent, and track loss."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def gradient(X, y, theta, lam):\n",
    "    preds = X @ theta\n",
    "    grad_mse = 2 * X.T @ (preds - y) / len(y)\n",
    "    grad_entropy = -1 - np.log(np.clip(theta, 1e-8, 1.0))\n",
    "    return grad_mse + lam * grad_entropy\n",
    "\n",
    "def fit_mirage(X, y, lam=0.1, eta=0.1, n_iters=300):\n",
    "    n = X.shape[1]\n",
    "    theta = np.ones(n) / n\n",
    "    loss_hist = []\n",
    "    for i in range(n_iters):\n",
    "        grad = gradient(X, y, theta, lam)\n",
    "        theta = mirror_descent_step(grad, theta, eta)\n",
    "        loss_hist.append(loss(X, y, theta, lam))\n",
    "    return theta, loss_hist\n",
    "\n",
    "theta_mirage, loss_hist = fit_mirage(X, y, lam=0.1, eta=0.2, n_iters=200)\n",
    "print('Final MIRAGE++ weights:', theta_mirage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Learning\n",
    "\n",
    "Let's plot the loss over iterations to see if the model is learning."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_hist)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('MIRAGE++ Training Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Compare to OLS, Ridge, and Lasso\n",
    "\n",
    "Let's see how MIRAGE++ weights compare to standard models."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "ols = LinearRegression().fit(X, y)\n",
    "ridge = Ridge(alpha=0.1).fit(X, y)\n",
    "lasso = Lasso(alpha=0.1).fit(X, y)\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.bar(np.arange(5)-0.3, ols.coef_, width=0.2, label='OLS')\n",
    "plt.bar(np.arange(5)-0.1, ridge.coef_, width=0.2, label='Ridge')\n",
    "plt.bar(np.arange(5)+0.1, lasso.coef_, width=0.2, label='Lasso')\n",
    "plt.bar(np.arange(5)+0.3, theta_mirage, width=0.2, label='MIRAGE++')\n",
    "plt.legend()\n",
    "plt.xlabel('Feature Index')\n",
    "plt.ylabel('Weight')\n",
    "plt.title('Model Weights Comparison')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. What Did We Learn?\n",
    "\n",
    "- MIRAGE++ produces weights that are positive, sum to 1, and are more diversified.\n",
    "- OLS, Ridge, and Lasso can have negative or highly concentrated weights.\n",
    "- Entropy regularization and mirror descent give us a new, interpretable solution.\n",
    "\n",
    "In the next notebook, we'll apply MIRAGE++ to more realistic finance problems!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
